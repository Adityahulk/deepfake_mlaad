{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¯ AASIST Model Evaluation on ASVspoof 2019 LA\n",
                "\n",
                "Evaluates the AASIST-inspired anti-spoofing model trained on MLAAD.\n",
                "\n",
                "**Run Cell 1, then RESTART RUNTIME, then continue from Cell 2.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 1: Install dependencies\n",
                "!pip uninstall datasets -y -q 2>/dev/null\n",
                "!pip install datasets==2.14.7 soundfile librosa -q\n",
                "print(\"âœ… Done! RESTART RUNTIME: Runtime â†’ Restart runtime\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 2: Upload model weights\n",
                "from google.colab import files\n",
                "print(\"ðŸ“¤ Upload aasist_best.pth:\")\n",
                "uploaded = files.upload()\n",
                "MODEL_PATH = list(uploaded.keys())[0]\n",
                "print(f\"âœ… Using: {MODEL_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 3: Imports and config\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torchaudio.transforms as T\n",
                "import numpy as np\n",
                "from sklearn.metrics import roc_curve\n",
                "from datasets import load_dataset\n",
                "from tqdm.auto import tqdm\n",
                "import math\n",
                "import gc\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "SAMPLE_RATE = 16000\n",
                "MAX_LEN = SAMPLE_RATE * 4\n",
                "SINC_CHANNELS = 70\n",
                "ENCODER_DIM = 128\n",
                "\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 4: AASIST Model Definition\n",
                "\n",
                "class SincConv(nn.Module):\n",
                "    def __init__(self, out_channels=70, kernel_size=251, sample_rate=16000, \n",
                "                 min_low_hz=50, min_band_hz=50):\n",
                "        super().__init__()\n",
                "        self.out_channels = out_channels\n",
                "        self.kernel_size = kernel_size\n",
                "        self.sample_rate = sample_rate\n",
                "        self.min_low_hz = min_low_hz\n",
                "        self.min_band_hz = min_band_hz\n",
                "        \n",
                "        low_hz = 30\n",
                "        high_hz = sample_rate / 2 - (min_low_hz + min_band_hz)\n",
                "        mel_low = 2595 * np.log10(1 + low_hz / 700)\n",
                "        mel_high = 2595 * np.log10(1 + high_hz / 700)\n",
                "        mel_points = np.linspace(mel_low, mel_high, out_channels + 1)\n",
                "        hz_points = 700 * (10 ** (mel_points / 2595) - 1)\n",
                "        \n",
                "        self.low_hz_ = nn.Parameter(torch.Tensor(hz_points[:-1]).view(-1, 1))\n",
                "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz_points)).view(-1, 1))\n",
                "        \n",
                "        n_lin = torch.linspace(0, (kernel_size / 2) - 1, steps=kernel_size // 2)\n",
                "        self.window_ = 0.54 - 0.46 * torch.cos(2 * math.pi * n_lin / kernel_size)\n",
                "        \n",
                "        n = (kernel_size - 1) / 2.0\n",
                "        self.n_ = 2 * math.pi * torch.arange(-n, 0).view(1, -1) / sample_rate\n",
                "        \n",
                "    def forward(self, x):\n",
                "        self.n_ = self.n_.to(x.device)\n",
                "        self.window_ = self.window_.to(x.device)\n",
                "        \n",
                "        low = self.min_low_hz + torch.abs(self.low_hz_)\n",
                "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_), \n",
                "                          self.min_low_hz, self.sample_rate / 2)\n",
                "        band = (high - low)[:, 0]\n",
                "        \n",
                "        f_low = low / self.sample_rate\n",
                "        f_high = high / self.sample_rate\n",
                "        \n",
                "        band_pass_left = ((torch.sin(f_high * self.n_) - torch.sin(f_low * self.n_)) / \n",
                "                         (self.n_ / 2)) * self.window_\n",
                "        band_pass_center = 2 * band.view(-1, 1)\n",
                "        band_pass_right = torch.flip(band_pass_left, dims=[1])\n",
                "        \n",
                "        band_pass = torch.cat([band_pass_left, band_pass_center, band_pass_right], dim=1)\n",
                "        band_pass = band_pass / (2 * band[:, None])\n",
                "        filters = band_pass.view(self.out_channels, 1, self.kernel_size)\n",
                "        \n",
                "        return F.conv1d(x, filters, stride=1, padding=self.kernel_size // 2)\n",
                "\n",
                "class SEBlock(nn.Module):\n",
                "    def __init__(self, channels, reduction=8):\n",
                "        super().__init__()\n",
                "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
                "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
                "    def forward(self, x):\n",
                "        y = x.mean(dim=2) if x.dim() == 3 else x.mean(dim=[2, 3])\n",
                "        y = F.relu(self.fc1(y))\n",
                "        y = torch.sigmoid(self.fc2(y))\n",
                "        return x * y.unsqueeze(2) if x.dim() == 3 else x * y.unsqueeze(2).unsqueeze(3)\n",
                "\n",
                "class Res2NetBlock(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch, scale=4, stride=1):\n",
                "        super().__init__()\n",
                "        width = out_ch // scale\n",
                "        self.scale = scale\n",
                "        self.width = width\n",
                "        self.conv1 = nn.Conv1d(in_ch, width * scale, 1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm1d(width * scale)\n",
                "        self.convs = nn.ModuleList([nn.Conv1d(width, width, 3, stride=stride, padding=1, bias=False) for _ in range(scale - 1)])\n",
                "        self.bns = nn.ModuleList([nn.BatchNorm1d(width) for _ in range(scale - 1)])\n",
                "        self.conv3 = nn.Conv1d(width * scale, out_ch, 1, bias=False)\n",
                "        self.bn3 = nn.BatchNorm1d(out_ch)\n",
                "        self.se = SEBlock(out_ch)\n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_ch != out_ch:\n",
                "            self.shortcut = nn.Sequential(nn.Conv1d(in_ch, out_ch, 1, stride=stride, bias=False), nn.BatchNorm1d(out_ch))\n",
                "    def forward(self, x):\n",
                "        identity = x\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        spx = torch.split(out, self.width, dim=1)\n",
                "        sp = []\n",
                "        for i in range(self.scale):\n",
                "            if i == 0: sp.append(spx[i])\n",
                "            elif i == 1: sp.append(F.relu(self.bns[i-1](self.convs[i-1](spx[i]))))\n",
                "            else: sp.append(F.relu(self.bns[i-1](self.convs[i-1](spx[i] + sp[-1]))))\n",
                "        out = torch.cat(sp, dim=1)\n",
                "        out = self.bn3(self.conv3(out))\n",
                "        out = self.se(out)\n",
                "        return F.relu(out + self.shortcut(identity))\n",
                "\n",
                "class GraphAttentionLayer(nn.Module):\n",
                "    def __init__(self, in_dim, out_dim, num_heads=4):\n",
                "        super().__init__()\n",
                "        self.num_heads = num_heads\n",
                "        self.head_dim = out_dim // num_heads\n",
                "        self.q = nn.Linear(in_dim, out_dim)\n",
                "        self.k = nn.Linear(in_dim, out_dim)\n",
                "        self.v = nn.Linear(in_dim, out_dim)\n",
                "        self.out = nn.Linear(out_dim, out_dim)\n",
                "    def forward(self, x):\n",
                "        b, n, _ = x.size()\n",
                "        q = self.q(x).view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        k = self.k(x).view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        v = self.v(x).view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        attn = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
                "        attn = F.softmax(attn, dim=-1)\n",
                "        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(b, n, -1)\n",
                "        return self.out(out)\n",
                "\n",
                "class AASISTEncoder(nn.Module):\n",
                "    def __init__(self, sinc_channels=70, encoder_dim=128):\n",
                "        super().__init__()\n",
                "        self.sinc = SincConv(out_channels=sinc_channels, kernel_size=251)\n",
                "        self.sinc_bn = nn.BatchNorm1d(sinc_channels)\n",
                "        self.sinc_pool = nn.MaxPool1d(3)\n",
                "        self.res2net = nn.Sequential(\n",
                "            Res2NetBlock(sinc_channels, 64, scale=4), nn.MaxPool1d(3),\n",
                "            Res2NetBlock(64, 128, scale=4), nn.MaxPool1d(3),\n",
                "            Res2NetBlock(128, 256, scale=4), nn.MaxPool1d(3),\n",
                "            Res2NetBlock(256, encoder_dim, scale=4))\n",
                "        self.gat = GraphAttentionLayer(encoder_dim, encoder_dim, num_heads=4)\n",
                "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
                "        self.fc = nn.Linear(encoder_dim, 2)\n",
                "    def forward(self, x):\n",
                "        x = self.sinc(x)\n",
                "        x = F.relu(self.sinc_bn(x))\n",
                "        x = self.sinc_pool(x)\n",
                "        x = self.res2net(x)\n",
                "        x = x.transpose(1, 2)\n",
                "        x = x + self.gat(x)\n",
                "        x = x.transpose(1, 2)\n",
                "        x = self.pool(x).squeeze(-1)\n",
                "        return x, self.fc(x)\n",
                "\n",
                "print(\"âœ… Model defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 5: Load model\n",
                "model = AASISTEncoder(sinc_channels=SINC_CHANNELS, encoder_dim=ENCODER_DIM).to(DEVICE)\n",
                "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))\n",
                "model.eval()\n",
                "print(\"âœ… Model loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 6: Load ASVspoof dataset\n",
                "print(\"ðŸ“¥ Loading ASVspoof 2019 LA eval...\")\n",
                "hf_ds = load_dataset(\"Bisher/ASVspoof_2019_LA\", split=\"eval\", streaming=False)\n",
                "print(f\"âœ… {len(hf_ds)} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 7: Dataset wrapper for raw waveform\n",
                "class HFDataset(Dataset):\n",
                "    def __init__(self, hf_ds):\n",
                "        self.ds = hf_ds\n",
                "    def __len__(self):\n",
                "        return len(self.ds)\n",
                "    def __getitem__(self, idx):\n",
                "        item = self.ds[idx]\n",
                "        audio = torch.FloatTensor(item['audio']['array'])\n",
                "        sr = item['audio']['sampling_rate']\n",
                "        if sr != SAMPLE_RATE:\n",
                "            audio = T.Resample(sr, SAMPLE_RATE)(audio)\n",
                "        if audio.shape[0] > MAX_LEN:\n",
                "            audio = audio[:MAX_LEN]\n",
                "        else:\n",
                "            audio = torch.cat([audio, torch.zeros(MAX_LEN - audio.shape[0])])\n",
                "        label = int(item['key'])  # 0=bonafide, 1=spoof\n",
                "        return audio.unsqueeze(0), label  # (1, T)\n",
                "\n",
                "dataset = HFDataset(hf_ds)\n",
                "test_audio, test_label = dataset[0]\n",
                "print(f\"âœ… Dataset works! Shape: {test_audio.shape}, Label: {test_label}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 8: Run evaluation\n",
                "def calc_eer(labels, scores):\n",
                "    fpr, tpr, _ = roc_curve(labels, scores, pos_label=1)\n",
                "    fnr = 1 - tpr\n",
                "    idx = np.nanargmin(np.abs(fpr - fnr))\n",
                "    return (fpr[idx] + fnr[idx]) / 2\n",
                "\n",
                "print(f\"ðŸš€ Evaluating {len(dataset)} samples...\")\n",
                "\n",
                "all_labels = []\n",
                "all_scores = []\n",
                "BATCH = 32\n",
                "\n",
                "with torch.no_grad():\n",
                "    for start in tqdm(range(0, len(dataset), BATCH)):\n",
                "        batch_audio = []\n",
                "        batch_labels = []\n",
                "        for i in range(start, min(start + BATCH, len(dataset))):\n",
                "            audio, label = dataset[i]\n",
                "            batch_audio.append(audio)\n",
                "            batch_labels.append(label)\n",
                "        \n",
                "        batch_tensor = torch.stack(batch_audio).to(DEVICE)\n",
                "        _, logits = model(batch_tensor)\n",
                "        probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
                "        \n",
                "        all_labels.extend(batch_labels)\n",
                "        all_scores.extend(probs)\n",
                "        \n",
                "        if start % 5000 == 0:\n",
                "            gc.collect()\n",
                "            torch.cuda.empty_cache()\n",
                "\n",
                "print(f\"\\nâœ… Processed {len(all_scores)} samples\")\n",
                "print(f\"Bonafide: {all_labels.count(0)}, Spoof: {all_labels.count(1)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 9: Calculate EER\n",
                "eer = calc_eer(all_labels, all_scores)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(f\"ðŸŽ¯ ASVspoof 2019 LA Eval EER: {eer * 100:.2f}%\")\n",
                "print(\"=\"*50)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}